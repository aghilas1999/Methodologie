{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4065379e",
   "metadata": {},
   "source": [
    "# SMAIL AGHILAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd60d9",
   "metadata": {},
   "source": [
    "# MLOps Exercise: Medical Image Classification with Chest X-Ray Images\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you'll gain practical experience with MLOps (Machine Learning Operations) by working on a real-world problem: classifying chest X-ray images to diagnose pneumonia. You'll go through various stages, from data cleaning to deployment, learning how to manage an end-to-end machine learning pipeline.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Basic understanding of Python\n",
    "- Familiarity with machine learning concepts\n",
    "- Experience with Jupyter Notebooks\n",
    "\n",
    "### Tools and Libraries\n",
    "\n",
    "- Python\n",
    "- NumPy\n",
    "- OpenCV\n",
    "- TensorFlow/Keras\n",
    "- scikit-learn\n",
    "- Flask\n",
    "- Matplotlib\n",
    "- imbalanced-learn\n",
    "\n",
    "These libraries should cover most requirements for this exercise, including data manipulation (NumPy, pandas), visualization (Matplotlib), machine learning (scikit-learn, TensorFlow), image processing (OpenCV), and class imbalance treatment (imbalanced-learn).\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Data Loading and Cleaning](#Data-Loading-and-Cleaning)\n",
    "2. [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis-(EDA))\n",
    "3. [Class Imbalance](#Class-Imbalance)\n",
    "4. [Model Building](#Model-Building)\n",
    "5. [Data Augmentation](#Data-Augmentation)\n",
    "6. [Model Evaluation](#Model-Evaluation)\n",
    "7. [Model Deployment (Bonus)](#Model-Deployment-(Bonus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1798b",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Before we begin, let's set up the environment. We'll install the necessary Python packages for this exercise.\n",
    "\n",
    "```bash\n",
    "pip install numpy pandas opencv-python matplotlib scikit-learn tensorflow flask\n",
    "```\n",
    "\n",
    "You can also create a `requirements.txt` file with the above packages and install them using `pip install -r requirements.txt`.\n",
    "Be aware that you should download ipykernel and export your env to the jupyter notebook.\n",
    "```bash\n",
    "python -m ipykernel install --user --name=my_new_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44e435",
   "metadata": {},
   "source": [
    "## Data Loading and Cleaning\n",
    "\n",
    "### Objective\n",
    "\n",
    "Load the dataset and clean it by removing corrupted images.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Download the Chest X-Ray Images (Pneumonia) dataset and place it in a directory accessible by this notebook. From https://ametice.univ-amu.fr\n",
    "2. Unzip the dataset and explore its directory structure.\n",
    "3. Load the images and labels for training.\n",
    "4. Write a function to scan for and remove any corrupted or invalid images.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Now, load the dataset use the zipfile library and clean it by removing corrupted images. Write your code in the cell below.\n",
    "\n",
    "```python\n",
    "import zipfile\n",
    "\n",
    "zip_file_path = 'path/to/your/zip/file.zip'\n",
    "extract_path = 'path/to/extract/folder'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "```\n",
    "\n",
    "After extracting, your dataset should have the following folder structure:\n",
    "\n",
    "```\n",
    "/\n",
    "|-- test/\n",
    "|   |-- NORMAL/\n",
    "|   |-- PNEUMONIA/\n",
    "|-- train/\n",
    "|   |-- NORMAL/\n",
    "|   |-- PNEUMONIA/\n",
    "|-- val/\n",
    "    |-- NORMAL/\n",
    "    |-- PNEUMONIA/\n",
    "```\n",
    "\n",
    "You can point `train_path` and `test_path` to the `train` and `test` folders inside this extracted directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1750bf33",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/Dataset.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16368\\4271949647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/raw/Dataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1248\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1249\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/Dataset.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_path = 'data/raw/Dataset.zip'\n",
    "extract_path = 'data/raw/Dataset'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569f917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def remove(folder_path):\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        path = os.path.join(folder_path, subfolder)\n",
    "        if os.path.isdir(path):\n",
    "            for im_file in os.listdir(path):\n",
    "                im_path = os.path.join(path, im_file)\n",
    "                try:\n",
    "                    # Essayer d'ouvrir le fichier image\n",
    "                    img = Image.open(im_path)\n",
    "                    img.verify()  \n",
    "                except (IOError, SyntaxError) :\n",
    "                    print(f\"Suppression de {im_path}\")\n",
    "                    os.remove(im_path)\n",
    "\n",
    "train_folder = 'data/raw/Dataset/chest_xray/chest_xray/train'\n",
    "test_folder = 'data/raw/Dataset/chest_xray/chest_xray/test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f8981",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Objective\n",
    "\n",
    "Understand the dataset's basic statistics and visualize the data.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Use matplotlib to visualize some sample images from each class.\n",
    "2. Investigate the distribution of classes (Pneumonia/Normal).\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Perform exploratory data analysis on the dataset. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfe6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_folder = 'data/raw/Dataset'\n",
    "for root, dirs, files in os.walk(dataset_folder):\n",
    "    print(f'Dossier : {root}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4dbb6fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'data/raw/Dataset/chest_xray/chest_xray/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aghil\\OneDrive\\Bureau\\TP_Methodologie\\TP1\\notebooks\\MLOps_Exercise.ipynb Cellule 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Utilisez le chemin relatif à partir du répertoire de travail actuel\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m train_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata/raw/Dataset/chest_xray/chest_xray/train\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m display_random_images(train_folder)\n",
      "\u001b[1;32mc:\\Users\\aghil\\OneDrive\\Bureau\\TP_Methodologie\\TP1\\notebooks\\MLOps_Exercise.ipynb Cellule 9\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay_random_images\u001b[39m(train_folder, num_images\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     classes \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(train_folder)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     num_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aghil/OneDrive/Bureau/TP_Methodologie/TP1/notebooks/MLOps_Exercise.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(num_classes, num_images, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m5\u001b[39m\u001b[39m*\u001b[39mnum_classes))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'data/raw/Dataset/chest_xray/chest_xray/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def display_random_images(train_folder, num_images=5):\n",
    "    classes = os.listdir(train_folder)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    fig, axes = plt.subplots(num_classes, num_images, figsize=(15, 5*num_classes))\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_folder = os.path.join(train_folder, class_name)\n",
    "        image_files = os.listdir(class_folder)\n",
    "        random_images = random.sample(image_files, num_images)\n",
    "        \n",
    "        for j, image_file in enumerate(random_images):\n",
    "            image_path = os.path.join(class_folder, image_file)\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            if num_classes == 1:\n",
    "                axes[j].imshow(image)\n",
    "                axes[j].set_title(f'{class_name}')\n",
    "            else:\n",
    "                axes[i, j].imshow(image)\n",
    "                axes[i, j].set_title(f'{class_name}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Utilisez le chemin relatif à partir du répertoire de travail actuel\n",
    "train_folder = 'data/raw/Dataset/chest_xray/chest_xray/train'\n",
    "display_random_images(train_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8645adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre d images dans la classe \"NORMAL\" dans le TEST est : 234\n",
      "Le nombre d images dans la classe \"PNEUMONIA\" dans le TEST est : 390\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_class_distribution(test_folder):\n",
    "    test_c = os.listdir(test_folder)\n",
    "\n",
    "    # Initialisez les compteurs pour chaque classe pour le test\n",
    "    test = {'NORMAL': 0, 'PNEUMONIA': 0}\n",
    "\n",
    "    # Calculer le nombre d'images pour chaque classe donnée et l'afficher pour savoir si c'est NORMAL ou PNEUMONIA\n",
    "    for classN in test_c:\n",
    "        class_f = os.path.join(test_folder, classN)\n",
    "        image_f = os.listdir(class_f)\n",
    "\n",
    "        if classN == 'NORMAL':\n",
    "            test['NORMAL'] += len(image_f)\n",
    "        elif classN == 'PNEUMONIA':\n",
    "            test['PNEUMONIA'] += len(image_f)\n",
    "\n",
    "        print(f'Le nombre d images dans la classe \"{classN}\" dans le TEST est : {len(image_f)}')\n",
    "\n",
    "    # Afficher la distribution des classes dans le répertoire de test\n",
    "    plt.bar(test.keys(), test.values())\n",
    "    plt.title('La distribution dans la classe TEST')\n",
    "    plt.show()\n",
    "\n",
    "test_folder = 'Dataset/chest_xray/test'\n",
    "plot_class_distribution(test_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292266c",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "\n",
    "### Objective\n",
    "\n",
    "Understand how class imbalance affects model performance and learn ways to mitigate it.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Train a baseline model without accounting for class imbalance.\n",
    "2. Evaluate its performance using metrics like accuracy, precision, recall, and F1-score.\n",
    "3. Experiment with techniques like class weighting or oversampling methods like SMOTE to balance the classes.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Address the class imbalance and evaluate the impact on the model. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0753462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bc6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"Dataset/chest_xray\"\n",
    "train_path = os.path.join(main_path,\"train\")\n",
    "test_path=os.path.join(main_path,\"test\")\n",
    "val_path=os.path.join(main_path,\"val\")\n",
    "\n",
    "train_normal = glob.glob(train_path+\"/NORMAL/*.jpeg\")\n",
    "train_pneumonia = glob.glob(train_path+\"/PNEUMONIA/*.jpeg\")\n",
    "\n",
    "test_normal = glob.glob(test_path+\"/NORMAL/*.jpeg\")\n",
    "test_pneumonia = glob.glob(test_path+\"/PNEUMONIA/*.jpeg\")\n",
    "\n",
    "val_normal=glob.glob(val_path+\"/NORMAL/*.jpeg\")\n",
    "val_pneumonia=glob.glob(val_path+\"/PNEUMONIA/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c8330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [x for x in train_normal]\n",
    "train_list.extend([x for x in train_pneumonia])\n",
    "\n",
    "df_train = pd.DataFrame(np.concatenate([['Normal']*len(train_normal) , ['Pneumonia']*len(train_pneumonia)]), columns = ['class'])\n",
    "df_train['image'] = [x for x in train_list]\n",
    "\n",
    "test_list = [x for x in test_normal]\n",
    "test_list.extend([x for x in test_pneumonia])\n",
    "\n",
    "df_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*len(test_pneumonia)]), columns = ['class'])\n",
    "df_test['image'] = [x for x in test_list]\n",
    "\n",
    "val_list=[x for x in val_normal]\n",
    "val_list.extend([x for x in val_pneumonia])\n",
    "\n",
    "df_val=pd.DataFrame(np.concatenate([['Normal']*len(val_normal) , ['Pneumonia']*len(val_pneumonia)]), columns = ['class'])\n",
    "df_val['image'] = [x for x in val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c50f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense)\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d3e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  \n",
    "    return image\n",
    "\n",
    "# Prétraitement des données d'entraînement, de test et de validation\n",
    "X_train = np.array([preprocess_image(img_path) for img_path in df_train['image']])\n",
    "X_test = np.array([preprocess_image(img_path) for img_path in df_test['image']])\n",
    "X_val = np.array([preprocess_image(img_path) for img_path in df_val['image']])\n",
    "\n",
    "y_train = df_train['class'].values\n",
    "y_test = df_test['class'].values\n",
    "y_val = df_val['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d7822e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal' 'Normal' 'Normal' 'Normal' 'Normal']\n",
      "['Normal' 'Normal' 'Normal' 'Normal' 'Normal']\n",
      "['Normal' 'Normal' 'Normal' 'Normal' 'Normal']\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])\n",
    "print(y_test[:5])\n",
    "print(y_val[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7703df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.35      0.51       234\n",
      "   Pneumonia       0.72      0.99      0.83       390\n",
      "\n",
      "    accuracy                           0.75       624\n",
      "   macro avg       0.84      0.67      0.67       624\n",
      "weighted avg       0.81      0.75      0.71       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "y_pred = svm_model.predict(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce00207",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "### Objective\n",
    "\n",
    "Build and train a deep learning model for image classification.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Use a Convolutional Neural Network (CNN) for this task.\n",
    "2. Experiment with different architectures and hyperparameters.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Build and train your model. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a8ba1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Créez un objet LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encodez les étiquettes d'entraînement, de test et de validation en format numérique\n",
    "y1_train = label_encoder.fit_transform(y_train)\n",
    "y1_test = label_encoder.transform(y_test)\n",
    "y1_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67db6008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               23888000  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23907521 (91.20 MB)\n",
      "Trainable params: 23907521 (91.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Création du modèle CNN\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  \n",
    "])\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b39fd43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 [==============================] - 121s 733ms/step - loss: 0.3980 - accuracy: 0.8675 - val_loss: 0.4411 - val_accuracy: 0.7500\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 117s 719ms/step - loss: 0.1000 - accuracy: 0.9626 - val_loss: 0.1473 - val_accuracy: 0.9375\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 117s 715ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 0.0917 - val_accuracy: 0.9375\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 119s 728ms/step - loss: 0.0575 - accuracy: 0.9797 - val_loss: 0.1368 - val_accuracy: 0.9375\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 119s 727ms/step - loss: 0.0533 - accuracy: 0.9801 - val_loss: 0.6004 - val_accuracy: 0.8125\n",
      "20/20 [==============================] - 2s 107ms/step - loss: 1.4227 - accuracy: 0.6987\n",
      "Accuracy on test data: 0.6987179517745972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(X_train, y1_train, epochs=5, validation_data=(X_val, y1_val))\n",
    "\n",
    "# Évaluation du modèle sur les données de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y1_test)\n",
    "print(f'Accuracy on test data: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce56b790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.6987179517745972\n",
      "loss on test data: 1.422726035118103\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on test data: {test_acc}')\n",
    "print(f'loss on test data: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4ed39",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "### Objective\n",
    "\n",
    "Improve your model's performance by using data augmentation techniques.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Apply data augmentation techniques like rotation, flipping, and zooming to generate more training data.\n",
    "2. Retrain your model using the augmented dataset.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Apply data augmentation techniques and evaluate the impact on the model. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d44c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d393980",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "### Objective\n",
    "\n",
    "Evaluate your model's performance using different metrics and visualization tools.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Use metrics like accuracy, precision, recall, and F1-score for evaluation.\n",
    "2. Plot confusion matrices and ROC curves to visualize your model's performance.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Evaluate your model and interpret the results. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here for Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749d240",
   "metadata": {},
   "source": [
    "## Model Deployment (Bonus)\n",
    "\n",
    "### Objective\n",
    "\n",
    "Learn the basics of deploying a machine learning model.\n",
    "\n",
    "### Guidance\n",
    "\n",
    "1. Save your trained model.\n",
    "2. Use Flask to create a simple REST API to serve your model.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Deploy your model using Flask. Write your code in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here for Model Deployment (Bonus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec894",
   "metadata": {},
   "source": [
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Experiment with more advanced architectures and hyperparameters.\n",
    "2. Deploy your model\n",
    "3. Integrate your model into a web application or other services.\n",
    "4. Learn more about MLOps best practices and tools.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
